{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import tritonclient.http as triton_http\n",
    "import orjson\n",
    "from google.api import httpbody_pb2\n",
    "from google.cloud import aiplatform as aip\n",
    "from google.cloud import aiplatform_v1 as gapic\n",
    "from transformers import AutoTokenizer\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "import asyncio\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OutputTensor:\n",
    "    name: str\n",
    "    shape: list\n",
    "    datatype: list[int]\n",
    "    data: list\n",
    "\n",
    "    @staticmethod\n",
    "    def process_sparse(sv):\n",
    "        batch_size = sv.shape[0]\n",
    "        results = []\n",
    "        for batch in np.arange(batch_size):\n",
    "            mask = sv[batch][0] > 0\n",
    "            indices = sv[batch][0][mask]\n",
    "            values = sv[batch][1][mask]\n",
    "            results.append({'indices': indices, 'values': values})\n",
    "        return results\n",
    "\n",
    "    def __post_init__(self):\n",
    "        data_type_map = {\n",
    "            \"FP32\": np.float32,\n",
    "            \"FP16\": np.float16,\n",
    "            \"INT32\": np.int32,\n",
    "            \"INT64\": np.int64,\n",
    "        }\n",
    "        self.data = np.array(self.data,dtype=data_type_map[self.datatype]).reshape(self.shape) # type: ignore\n",
    "        if self.name == \"sparse_embedding\":\n",
    "            self.data = self.process_sparse(self.data)\n",
    "\n",
    "\n",
    "\n",
    "class EmbeddingWorkerVertexAI:\n",
    "    def __init__(self, task):\n",
    "        # Initialize client\n",
    "        if task == \"query\":\n",
    "            self.model_name = \"queryEmbed\"\n",
    "            self.task = 0\n",
    "        elif task == \"document\":\n",
    "            self.model_name = \"docEmbed\"\n",
    "            self.task = 1\n",
    "        else:\n",
    "            raise ValueError(\"Incorrect task (either 'query' or 'document')\")\n",
    "        self.input_names = [\"input_ids\", \"token_type_ids\", \"attention_mask\"]\n",
    "        self.output_names = [\"dense_embedding\", \"sparse_embedding\"]\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(\"../bert-tokenizer-hf/\")\n",
    "\n",
    "        self.headers = {\n",
    "            \"x-vertex-ai-triton-redirect\": f\"v2/models/{self.model_name}/infer\",\n",
    "        }\n",
    "        self.project_id = 341272062859\n",
    "        self.endpoint_id = 430471996413837312\n",
    "        self.location = \"asia-south1\"\n",
    "        if self.task == 1:\n",
    "            self.tokenizer = partial(\n",
    "                self._tokenizer,\n",
    "                padding=\"longest\",\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"np\",\n",
    "            )\n",
    "        else:\n",
    "            self.tokenizer = partial(\n",
    "                self._tokenizer,\n",
    "                padding=\"longest\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "                return_tensors=\"np\",\n",
    "            )\n",
    "        self.api_endpoint = f\"projects/{self.project_id}/locations/{self.location}/endpoints/{self.endpoint_id}\"\n",
    "        self.client_api_endpoint: str = \"asia-south1-aiplatform.googleapis.com\"\n",
    "        self.client_options = {\"api_endpoint\": self.client_api_endpoint}\n",
    "        self.gapic_client = gapic.PredictionServiceClient(\n",
    "            client_options=self.client_options\n",
    "        )\n",
    "        self.triton_output_http = [\n",
    "            triton_http.InferRequestedOutput(name=output_name, binary_data=False)\n",
    "            for output_name in self.output_names\n",
    "        ]\n",
    "\n",
    "    def prepare_inputs(self, payload):\n",
    "        if isinstance(payload, str):\n",
    "            payload = [payload]\n",
    "        else:\n",
    "            pass\n",
    "        tokens = self.tokenizer(payload)\n",
    "        tokens = {k: np.array(v.tolist()) for k, v in tokens.items()}\n",
    "        inputs = [\n",
    "            triton_http.InferInput(\n",
    "                name=input_name, shape=tokens[input_name].shape, datatype=\"INT64\"\n",
    "            ).set_data_from_numpy(tokens[input_name],binary_data=False)\n",
    "            for input_name in self.input_names\n",
    "        ]\n",
    "        return inputs\n",
    "\n",
    "    def infer_request(self, payload):\n",
    "        _data, _ = triton_http._utils._get_inference_request(\n",
    "            inputs=self.prepare_inputs(payload),\n",
    "            outputs=self.triton_output_http,\n",
    "            # outputs=None,\n",
    "            request_id=\"1\",\n",
    "            sequence_id=0,\n",
    "            sequence_start=False,\n",
    "            sequence_end=False,\n",
    "            priority=0,\n",
    "            timeout=None,\n",
    "            custom_parameters=None,\n",
    "        )\n",
    "        http_body = httpbody_pb2.HttpBody(data=_data, content_type=\"application/json\")  # type: ignore\n",
    "        # print(f\"request: {http_body}\")\n",
    "        request = gapic.RawPredictRequest(\n",
    "            endpoint=\"projects/341272062859/locations/asia-south1/endpoints/430471996413837312\",\n",
    "            http_body=http_body,\n",
    "        )\n",
    "        response = self.gapic_client.raw_predict(\n",
    "            request=request, metadata=tuple(self.headers.items())\n",
    "        )\n",
    "        response = orjson.loads(response.data) # type: ignore\n",
    "        response = [OutputTensor(**output) for output in response[\"outputs\"]]\n",
    "        return response\n",
    "    \n",
    "    def profile_embed(self,payload):\n",
    "        start = time.perf_counter()\n",
    "        response = self.infer_request(payload)\n",
    "        end = time.perf_counter()\n",
    "        print(f\"{end - start} seconds\")\n",
    "    \n",
    "    async def profile_async_embed(self,payload):\n",
    "        start = time.perf_counter()\n",
    "        # loop = asyncio.get_event_loop()\n",
    "        # response_dict = loop.run_in_execu/tor(None, self.infer_request, payload)\n",
    "        response = self.infer_request(payload)\n",
    "        end = time.perf_counter()\n",
    "        print(f\"{end - start} seconds\")\n",
    "    \n",
    "    async def embed(self,payload):\n",
    "        response = self.infer_request(payload)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker = EmbeddingWorkerVertexAI(\"query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await worker.embed(\"hello world\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
